{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing code: Clustering ONET description \n",
    "\n",
    "Phai Phongthiengtham: 11/06/2018\n",
    " \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U pyldavis\n",
    "#!pip install -U spacy\n",
    "#!pip install -U scikit-learn\n",
    "#!pip install -U https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
    "#!pip install -U nltk\n",
    "#!pip install -U gensim\n",
    "#import nltk\n",
    "#nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re, os, json, sys, csv, time, datetime, types\n",
    "import operator, curl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "# sklearn\n",
    "import sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "# scacy\n",
    "#import spacy\n",
    "#import en_core_web_sm\n",
    "#nlp = en_core_web_sm.load(disable=['parser', 'tagger','ner'] )\n",
    "\n",
    "# plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import pyLDAvis.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>Determine and formulate policies and provide o...</td>\n",
       "      <td>determine and formulate policy and provide ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1011.03</td>\n",
       "      <td>Chief Sustainability Officers</td>\n",
       "      <td>Communicate and coordinate with management, sh...</td>\n",
       "      <td>communicate and coordinate with management sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1021.00</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>Plan, direct, or coordinate the operations of ...</td>\n",
       "      <td>plan direct or coordinate the operation of pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-1031.00</td>\n",
       "      <td>Legislators</td>\n",
       "      <td>Develop, introduce or enact laws and statutes ...</td>\n",
       "      <td>develop introduce or enact law and statute at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-2011.00</td>\n",
       "      <td>Advertising and Promotions Managers</td>\n",
       "      <td>Plan, direct, or coordinate advertising polici...</td>\n",
       "      <td>plan direct or coordinate advertise policy and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  O*NET-SOC Code                                Title  \\\n",
       "0     11-1011.00                     Chief Executives   \n",
       "1     11-1011.03        Chief Sustainability Officers   \n",
       "2     11-1021.00      General and Operations Managers   \n",
       "3     11-1031.00                          Legislators   \n",
       "4     11-2011.00  Advertising and Promotions Managers   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Determine and formulate policies and provide o...   \n",
       "1  Communicate and coordinate with management, sh...   \n",
       "2  Plan, direct, or coordinate the operations of ...   \n",
       "3  Develop, introduce or enact laws and statutes ...   \n",
       "4  Plan, direct, or coordinate advertising polici...   \n",
       "\n",
       "                                           CleanText  \n",
       "0  determine and formulate policy and provide ove...  \n",
       "1  communicate and coordinate with management sha...  \n",
       "2  plan direct or coordinate the operation of pub...  \n",
       "3  develop introduce or enact law and statute at ...  \n",
       "4  plan direct or coordinate advertise policy and...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in text data\n",
    "df = pd.read_csv(\"ONET_preprocessed.txt\", sep = '\\t', header = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string replace\n",
    "def cleanup(text):\n",
    "    if text == '': # allows for possibility of being empty \n",
    "        output = ''\n",
    "    else:\n",
    "        text = text.replace(\"'s\", \" \")\n",
    "        text = text.replace(\"n't\", \" not \")\n",
    "        text = text.replace(\"'ve\", \" have \")\n",
    "        text = text.replace(\"'re\", \" are \")\n",
    "        text = text.replace(\"'m\",\"  am \")\n",
    "        text = text.replace(\"'ll\",\"  will \")\n",
    "        text = text.replace(\"-\",\" \")\n",
    "        text = text.replace(\"/\",\" \")\n",
    "        text = text.replace(\"(\",\" \")\n",
    "        text = text.replace(\")\",\" \")\n",
    "        text = re.sub(r'[^A-Za-z ]', '', text) #remove all characters that are not A-Z, a-z or 0-9\n",
    "        output = ' '.join([w for w in re.split(' ',text) if not w=='']) #remove extra spaces \n",
    "    return output  \n",
    "\n",
    "# pre-process text\n",
    "def main_preprocess(text):\n",
    "    text = str(text) # make sure the input is actually string\n",
    "    text = ''.join([i if ord(i) < 128 else ' ' for i in text])\n",
    "    if text == '': # allows for possibility of being empty \n",
    "        output = ''\n",
    "    else:\n",
    "        tokens = [w.lemma_.lower() for w in nlp(cleanup(text))] # cleanup and tokenize\n",
    "        output = ' '.join([w for w in tokens if not w==''])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Occupation Data.txt\", sep = '\\t', header = 0)\n",
    "df['CleanText'] = df['Description'].apply(lambda x: main_preprocess(x))\n",
    "print( df.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer\n",
    "* \"extra_remove_words\" : add extra words to be removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_remove_words = ['use','may','include','includes']\n",
    "stop_words = set(stop_words + extra_remove_words)\n",
    "\n",
    "min_df = 0.01\n",
    "max_df = 0.99\n",
    "max_ngram = 1\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = stop_words,\n",
    "                             min_df = min_df, \n",
    "                             max_df = max_df,\n",
    "                             ngram_range = (1,max_ngram))\n",
    "\n",
    "vectorizer.fit(df['CleanText'])\n",
    "vector = vectorizer.transform(df['CleanText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA\n",
    "* \"n_components\" is the number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=3, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components = 3,\n",
    "                                learning_method = 'online',\n",
    "                                random_state = 0,\n",
    "                                batch_size = 128,\n",
    "                                evaluate_every = -1)\n",
    "\n",
    "lda.fit(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cluster(lda, vectorizer, n_words=30):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "        df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "        df_topic_keywords.columns = ['word_' + str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "        df_topic_keywords['cluster'] = range(0,df_topic_keywords.shape[0])\n",
    "        df_topic_keywords.index = ['cluster_' + str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "    return df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>word_9</th>\n",
       "      <th>word_10</th>\n",
       "      <th>word_11</th>\n",
       "      <th>word_12</th>\n",
       "      <th>word_13</th>\n",
       "      <th>word_14</th>\n",
       "      <th>word_15</th>\n",
       "      <th>word_16</th>\n",
       "      <th>word_17</th>\n",
       "      <th>word_18</th>\n",
       "      <th>word_19</th>\n",
       "      <th>word_20</th>\n",
       "      <th>word_21</th>\n",
       "      <th>word_22</th>\n",
       "      <th>word_23</th>\n",
       "      <th>word_24</th>\n",
       "      <th>word_25</th>\n",
       "      <th>word_26</th>\n",
       "      <th>word_27</th>\n",
       "      <th>word_28</th>\n",
       "      <th>word_29</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cluster_0</th>\n",
       "      <td>system</td>\n",
       "      <td>design</td>\n",
       "      <td>control</td>\n",
       "      <td>test</td>\n",
       "      <td>separately</td>\n",
       "      <td>list</td>\n",
       "      <td>datum</td>\n",
       "      <td>conduct</td>\n",
       "      <td>engineer</td>\n",
       "      <td>assist</td>\n",
       "      <td>computer</td>\n",
       "      <td>apply</td>\n",
       "      <td>develop</td>\n",
       "      <td>air</td>\n",
       "      <td>information</td>\n",
       "      <td>patient</td>\n",
       "      <td>research</td>\n",
       "      <td>communication</td>\n",
       "      <td>process</td>\n",
       "      <td>analyze</td>\n",
       "      <td>aircraft</td>\n",
       "      <td>care</td>\n",
       "      <td>land</td>\n",
       "      <td>worker</td>\n",
       "      <td>study</td>\n",
       "      <td>animal</td>\n",
       "      <td>relate</td>\n",
       "      <td>monitor</td>\n",
       "      <td>fire</td>\n",
       "      <td>industrial</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_1</th>\n",
       "      <td>equipment</td>\n",
       "      <td>operate</td>\n",
       "      <td>material</td>\n",
       "      <td>machine</td>\n",
       "      <td>repair</td>\n",
       "      <td>perform</td>\n",
       "      <td>maintain</td>\n",
       "      <td>product</td>\n",
       "      <td>record</td>\n",
       "      <td>prepare</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>set</td>\n",
       "      <td>metal</td>\n",
       "      <td>tend</td>\n",
       "      <td>install</td>\n",
       "      <td>duty</td>\n",
       "      <td>work</td>\n",
       "      <td>tool</td>\n",
       "      <td>duties</td>\n",
       "      <td>clean</td>\n",
       "      <td>hand</td>\n",
       "      <td>power</td>\n",
       "      <td>form</td>\n",
       "      <td>part</td>\n",
       "      <td>process</td>\n",
       "      <td>order</td>\n",
       "      <td>require</td>\n",
       "      <td>variety</td>\n",
       "      <td>cut</td>\n",
       "      <td>assemble</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_2</th>\n",
       "      <td>activity</td>\n",
       "      <td>coordinate</td>\n",
       "      <td>teach</td>\n",
       "      <td>plan</td>\n",
       "      <td>direct</td>\n",
       "      <td>service</td>\n",
       "      <td>operation</td>\n",
       "      <td>individual</td>\n",
       "      <td>provide</td>\n",
       "      <td>supervise</td>\n",
       "      <td>engage</td>\n",
       "      <td>research</td>\n",
       "      <td>program</td>\n",
       "      <td>worker</td>\n",
       "      <td>train</td>\n",
       "      <td>teacher</td>\n",
       "      <td>organization</td>\n",
       "      <td>primarily</td>\n",
       "      <td>public</td>\n",
       "      <td>financial</td>\n",
       "      <td>combination</td>\n",
       "      <td>manage</td>\n",
       "      <td>course</td>\n",
       "      <td>social</td>\n",
       "      <td>management</td>\n",
       "      <td>transportation</td>\n",
       "      <td>establishment</td>\n",
       "      <td>facility</td>\n",
       "      <td>business</td>\n",
       "      <td>group</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word_0      word_1    word_2   word_3      word_4   word_5  \\\n",
       "cluster_0     system      design   control     test  separately     list   \n",
       "cluster_1  equipment     operate  material  machine      repair  perform   \n",
       "cluster_2   activity  coordinate     teach     plan      direct  service   \n",
       "\n",
       "              word_6      word_7    word_8     word_9   word_10   word_11  \\\n",
       "cluster_0      datum     conduct  engineer     assist  computer     apply   \n",
       "cluster_1   maintain     product    record    prepare   vehicle       set   \n",
       "cluster_2  operation  individual   provide  supervise    engage  research   \n",
       "\n",
       "           word_12 word_13      word_14  word_15       word_16        word_17  \\\n",
       "cluster_0  develop     air  information  patient      research  communication   \n",
       "cluster_1    metal    tend      install     duty          work           tool   \n",
       "cluster_2  program  worker        train  teacher  organization      primarily   \n",
       "\n",
       "           word_18    word_19      word_20 word_21 word_22 word_23  \\\n",
       "cluster_0  process    analyze     aircraft    care    land  worker   \n",
       "cluster_1   duties      clean         hand   power    form    part   \n",
       "cluster_2   public  financial  combination  manage  course  social   \n",
       "\n",
       "              word_24         word_25        word_26   word_27   word_28  \\\n",
       "cluster_0       study          animal         relate   monitor      fire   \n",
       "cluster_1     process           order        require   variety       cut   \n",
       "cluster_2  management  transportation  establishment  facility  business   \n",
       "\n",
       "              word_29  cluster  \n",
       "cluster_0  industrial        0  \n",
       "cluster_1    assemble        1  \n",
       "cluster_2       group        2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster = display_cluster(lda, vectorizer, n_words=30)\n",
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
